{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d1cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpu='0', data_type='Sample', data='./UTR-LM/Data/MRL_Random50Nuc_SynthesisLibrary_Sample/4.1_train_data_GSM3130435_egfp_unmod_1.csv', seq_type='utr', inp_len=50, pretrained=True, esm2_modelfile='./UTR-LM/Model/ESM2SISS_FS4.1_fiveSpeciesCao_6layers_16heads_128embedsize_4096batchToks_lr1e-05_supervisedweight1.0_structureweight1.0_MLMLossMin_epoch93.pkl', finetune=True, predictor_modelfile='./UTR-LM/Sample/saved_models/MJ3_seed1337_ESM2SISS_FS4.1.ep93.1e-2.dr5_unmod_1_utr_10folds_rl_LabelScalerFalse_LabelLog2False_AvgEmbFalse_BosEmbTrue_CNNlayer0_epoch300_nodes40_dropout30.5_finetuneTrue_huberlossTrue_lr0.01_fold0_epoch190.pt', logits=False, representations_pertok=False, representations_bos=True, representations_mean=False, attentions=False, attentions_symm=False, contacts=False)\n",
      "\n",
      " Pretrained_4.1_train__ESM2SISS_FS4.1_fiveSpeciesCao_6layers_16heads_128embedsize_4096batchToks_lr1e-05_supervisedweight1.0_structureweight1.0_MLMLossMin_epoch93\n",
      "\n",
      " Finetuned_4.1_train__MJ3_seed1337_ESM2SISS_FS4.1.ep93.1e-2.dr5_unmod_1_utr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from argparse import Namespace\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import esm\n",
    "from esm.data import *\n",
    "from esm.model.esm2_secondarystructure import ESM2 as ESM2_SISS\n",
    "from esm.model.esm2_supervised import ESM2\n",
    "from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, pretrained, MSATransformer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import r2_score, f1_score, roc_auc_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from collections import Counter\n",
    "os.chdir('/scratch/users/yanyichu/')\n",
    "seed = 1337\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--gpu', type = str, default = '0')\n",
    "parser.add_argument('--data_type', type = str, default = 'Sample')\n",
    "parser.add_argument('--data', type = str, default = './UTR-LM/Data/MRL_Random50Nuc_SynthesisLibrary_Sample/4.1_train_data_GSM3130435_egfp_unmod_1.csv')\n",
    "parser.add_argument('--seq_type', type = str, default = 'utr')\n",
    "parser.add_argument('--inp_len', type = int, default = 50)\n",
    "parser.add_argument('--pretrained', action = 'store_true') ## if --pretrained: True\n",
    "parser.add_argument('--esm2_modelfile', type = str, default = './UTR-LM/Model/ESM2_1.4_five_species_TrainLossMin_6layers_16heads_128embedsize_4096batchToks.pkl')\n",
    "\n",
    "parser.add_argument('--finetune', action = 'store_true') ## if --finetune: True\n",
    "parser.add_argument('--predictor_modelfile', type = str, default = './UTR-LM/Sample/saved_models/MJ3_seed1337_ESM2SISS_FS4.1.ep93.1e-2.dr5_unmod_1_utr_10folds_rl_LabelScalerFalse_LabelLog2False_AvgEmbFalse_BosEmbTrue_CNNlayer0_epoch300_nodes40_dropout30.5_finetuneTrue_huberlossTrue_lr0.01_fold0_epoch190.pt')\n",
    "\n",
    "parser.add_argument('--logits', action = 'store_true') ## ## if --: True\n",
    "parser.add_argument('--representations_pertok', action = 'store_true') ## if --: True\n",
    "parser.add_argument('--representations_bos', action = 'store_true') ## if --: True\n",
    "parser.add_argument('--representations_mean', action = 'store_true') ## if --: True\n",
    "parser.add_argument('--attentions', action = 'store_true') ## if --: True\n",
    "parser.add_argument('--attentions_symm', action = 'store_true') ## if --: True\n",
    "parser.add_argument('--contacts', action = 'store_true') ## if --: True\n",
    "    \n",
    "args = parser.parse_args(['--pretrained', '--esm2_modelfile', './UTR-LM/Model/ESM2SISS_FS4.1_fiveSpeciesCao_6layers_16heads_128embedsize_4096batchToks_lr1e-05_supervisedweight1.0_structureweight1.0_MLMLossMin_epoch93.pkl',#ESM2_1.4_five_species_TrainLossMin_6layers_16heads_128embedsize_4096batchToks.pkl',\n",
    "                          '--finetune', '--predictor_modelfile', './UTR-LM/Sample/saved_models/MJ3_seed1337_ESM2SISS_FS4.1.ep93.1e-2.dr5_unmod_1_utr_10folds_rl_LabelScalerFalse_LabelLog2False_AvgEmbFalse_BosEmbTrue_CNNlayer0_epoch300_nodes40_dropout30.5_finetuneTrue_huberlossTrue_lr0.01_fold0_epoch190.pt',\n",
    "                          '--representations_bos'])  # , '--representations_mean', '--attentions_symm', '--attentions'\n",
    "print(args)\n",
    "global layers, heads, embed_dim, batch_toks, cnn_layers, epoch, nodes, dropout3, modelfile, magic, avg_emb, bos_emb, inp_len\n",
    "inp_len = args.inp_len\n",
    "mask_prob = 0.0\n",
    "\n",
    "modelfile = args.predictor_modelfile\n",
    "output_dir = f'./UTR-LM/{args.data_type}/Embedding_Contacts'\n",
    "ESM2_results_outfilename = args.esm2_modelfile.split('/')[-1].replace('.pkl', '').replace('.pt', '')\n",
    "filename = args.predictor_modelfile.split('/')[-1].replace('.pkl', '').replace('.pt', '')\n",
    "\n",
    "cell_line = '_'.join(args.data.split('/')[-1].split('_')[:2])\n",
    "pretrained_outfilename = f'Pretrained_{cell_line}__{ESM2_results_outfilename}'.replace('_6layers_16heads_128embedsize_4096batchToks_MLMLossMin', '').replace('_huberlossTrue_magicFalse', '').replace('_AvgEmbFalse', '')\n",
    "finetuned_outfilename = f'Finetuned_{cell_line}__{\"_\".join(filename.split(\"/\")[-1].split(\"_\")[:7])}'.replace('_6layers_16heads_128embedsize_4096batchToks_MLMLossMin', '').replace('_huberlossTrue_magicFalse', '').replace('_AvgEmbFalse', '')\n",
    "\n",
    "print('\\n', pretrained_outfilename)\n",
    "print('\\n', finetuned_outfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1941eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 6\n",
    "heads = 16\n",
    "embed_dim = 128\n",
    "batch_toks = 4096\n",
    "\n",
    "predictor_model_info = args.predictor_modelfile.split('_')\n",
    "nodes = 40\n",
    "dropout3 = 0.5\n",
    "cnn_layers = 0\n",
    "epoch = int(args.predictor_modelfile.split('_')[-1][5:-3])\n",
    "avg_emb = False\n",
    "bos_emb = True\n",
    "magic = False\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "device = 'cpu'#torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "repr_layers = [0, layers]\n",
    "include = [\"mean\"]\n",
    "truncate = True\n",
    "return_contacts = True\n",
    "return_representation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966c5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_linear(nn.Module):\n",
    "    def __init__(self, \n",
    "                 border_mode='same', filter_len=8, nbr_filters=120,\n",
    "                 dropout1=0, dropout2=0):\n",
    "        \n",
    "        super(CNN_linear, self).__init__()\n",
    "        \n",
    "        self.embedding_size = embed_dim\n",
    "        self.border_mode = border_mode\n",
    "        self.inp_len = inp_len\n",
    "        self.nodes = nodes\n",
    "        self.cnn_layers = cnn_layers\n",
    "        self.filter_len = filter_len\n",
    "        self.nbr_filters = nbr_filters\n",
    "        self.dropout1 = dropout1\n",
    "        self.dropout2 = dropout2\n",
    "        self.dropout3 = dropout3\n",
    "        \n",
    "        if 'SISS' in args.predictor_modelfile:\n",
    "            self.esm2 = ESM2_SISS(num_layers = layers,\n",
    "                                     embed_dim = embed_dim,\n",
    "                                     attention_heads = heads,\n",
    "                                     alphabet = alphabet)\n",
    "        elif 'SS' in args.predictor_modelfile:\n",
    "            self.esm2 = ESM2_SS(num_layers = layers,\n",
    "                                     embed_dim = embed_dim,\n",
    "                                     attention_heads = heads,\n",
    "                                     alphabet = alphabet)\n",
    "        else:\n",
    "            self.esm2 = ESM2(num_layers = layers,\n",
    "                                     embed_dim = embed_dim,\n",
    "                                     attention_heads = heads,\n",
    "                                     alphabet = alphabet)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels = self.embedding_size, \n",
    "                      out_channels = self.nbr_filters, kernel_size = self.filter_len, padding = self.border_mode)\n",
    "        self.conv2 = nn.Conv1d(in_channels = self.nbr_filters, \n",
    "                      out_channels = self.nbr_filters, kernel_size = self.filter_len, padding = self.border_mode)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(self.dropout1)\n",
    "        self.dropout2 = nn.Dropout(self.dropout2)\n",
    "        self.dropout3 = nn.Dropout(self.dropout3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        if avg_emb or bos_emb:\n",
    "            self.fc = nn.Linear(in_features = embed_dim, out_features = self.nodes)\n",
    "        else:\n",
    "            self.fc = nn.Linear(in_features = inp_len * embed_dim, out_features = self.nodes)\n",
    "        if avg_emb or bos_emb:\n",
    "            self.linear = nn.Linear(in_features = self.nbr_filters, out_features = self.nodes)\n",
    "        else:\n",
    "            self.linear = nn.Linear(in_features = inp_len * self.nbr_filters, out_features = self.nodes)\n",
    "        self.output = nn.Linear(in_features = self.nodes, out_features = 1)\n",
    "        if self.cnn_layers == -1: self.direct_output = nn.Linear(in_features = embed_dim, out_features = 1)\n",
    "        if magic: self.magic_output = nn.Linear(in_features = 1, out_features = 1)\n",
    "            \n",
    "    def forward(self, tokens, need_head_weights=True, return_contacts=True, return_representation = True, return_attentions_symm = False, return_attentions = False):\n",
    "#         print(tokens.shape)\n",
    "        x_esm2 = self.esm2(tokens, repr_layers, need_head_weights, return_contacts, return_representation, return_attentions_symm, return_attentions)\n",
    "        if avg_emb:\n",
    "            x = x_esm2[\"representations\"][layers][:, 1 : inp_len+1].mean(1)\n",
    "            x_o = x.unsqueeze(2)\n",
    "        elif bos_emb:\n",
    "            x = x_esm2[\"representations\"][layers][:, 0]\n",
    "            x_o = x.unsqueeze(2)\n",
    "        else:\n",
    "            x_o = x_esm2[\"representations\"][layers][:, 1 : inp_len+1]\n",
    "            x_o = x_o.permute(0, 2, 1)\n",
    "\n",
    "        if self.cnn_layers >= 1:\n",
    "            x_cnn1 = self.conv1(x_o)\n",
    "            x_o = self.relu(x_cnn1)\n",
    "        if self.cnn_layers >= 2: \n",
    "            x_cnn2 = self.conv2(x_o)\n",
    "            x_relu2 = self.relu(x_cnn2)\n",
    "            x_o = self.dropout1(x_relu2)\n",
    "        if self.cnn_layers >= 3: \n",
    "            x_cnn3 = self.conv2(x_o)\n",
    "            x_relu3 = self.relu(x_cnn3)\n",
    "            x_o = self.dropout2(x_relu3)\n",
    "        \n",
    "#         if self.cnn_layers >= 1: \n",
    "        x = self.flatten(x_o)\n",
    "        if self.cnn_layers != -1:\n",
    "            if self.cnn_layers != 0:\n",
    "                o_linear = self.linear(x)\n",
    "            else:\n",
    "                o_linear = self.fc(x)\n",
    "            o_relu = self.relu(o_linear)\n",
    "            o_dropout = self.dropout3(o_relu)\n",
    "            o = self.output(o_dropout)\n",
    "        else:\n",
    "            o = self.direct_output(x)\n",
    "#         print(o.shape)\n",
    "        if magic:\n",
    "            o = self.magic_output(o)\n",
    "        return o, x_esm2, self.esm2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b8c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(x,y):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "    return r_value**2\n",
    "\n",
    "def performances(label, pred):\n",
    "    label, pred = list(label), list(pred)\n",
    "    \n",
    "    r = r2(label, pred)\n",
    "    R2 = r2_score(label, pred)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(label, pred))\n",
    "    mae = mean_absolute_error(label, pred)\n",
    "    \n",
    "    try:\n",
    "        pearson_r = pearsonr(label, pred)[0]\n",
    "    except:\n",
    "        pearson_r = -1e-9\n",
    "    try:\n",
    "        sp_cor = spearmanr(label, pred)[0]\n",
    "    except:\n",
    "        sp_cor = -1e-9\n",
    "    \n",
    "    print(f'r-squared = {r:.4f} | pearson r = {pearson_r:.4f} | spearman R = {sp_cor:.4f} | R-squared = {R2:.4f} | RMSE = {rmse:.4f} | MAE = {mae:.4f}')\n",
    "        \n",
    "    return [r, pearson_r, sp_cor, R2, rmse, mae]\n",
    "\n",
    "def performances_to_pd(performances_list):\n",
    "    performances_pd = pd.DataFrame(performances_list, index = ['r2', 'PearsonR', 'SpearmanR', 'R2', 'RMSE', 'MAE']).T\n",
    "    return performances_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff57a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, '<eos>': 1, '<unk>': 2, 'A': 3, 'G': 4, 'C': 5, 'T': 6, '<cls>': 7, '<mask>': 8, '<sep>': 9}\n",
      "260000 sequences with Max SeqLen = 50\n"
     ]
    }
   ],
   "source": [
    "alphabet = Alphabet(standard_toks = 'AGCT', mask_prob = mask_prob)\n",
    "print(alphabet.tok_to_idx)\n",
    "assert alphabet.tok_to_idx == {'<pad>': 0, '<eos>': 1, '<unk>': 2, 'A': 3, 'G': 4, 'C': 5, 'T': 6, '<cls>': 7, '<mask>': 8, '<sep>': 9}\n",
    "\n",
    "if args.data_type == 'Sample':\n",
    "    data = pd.read_csv(args.data)\n",
    "    data.rename(columns = {'rl':'label'}, inplace = True)\n",
    "    dataset = FastaBatchedDataset(data.loc[:,'label'], data.utr, mask_prob = mask_prob)\n",
    "elif args.data_type == 'Pretrained':\n",
    "    dataset = FastaBatchedDataset.from_file(args.data, mask_prob = mask_prob)\n",
    "elif args.data_type == 'Cao':\n",
    "    data = pd.read_csv(args.data)\n",
    "    data.rename(columns = {'te_log':'label'}, inplace = True)\n",
    "    dataset = FastaBatchedDataset(data.loc[:,'label'], data[args.seq_type].str[-args.inp_len:], mask_prob = mask_prob)\n",
    "else:\n",
    "    data = pd.read_csv(args.data)\n",
    "    dataset = FastaBatchedDataset(data.loc[:,'label'], data[args.seq_type].str[-args.inp_len:], mask_prob = mask_prob)\n",
    "\n",
    "batches = dataset.get_batch_indices(toks_per_batch=batch_toks, extra_toks_per_seq=2)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, \n",
    "    collate_fn=alphabet.get_batch_converter(),\n",
    "    batch_sampler=batches, \n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "if args.data_type == 'Pretrained': \n",
    "    max_seqlen = max([len(s[0]) for s in list(dataset)])\n",
    "else:\n",
    "    max_seqlen = max([len(s[1]) for s in list(dataset)])\n",
    "print(f\"{len(dataset)} sequences with Max SeqLen = {max_seqlen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab50e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetuned_eval_step(test_dataloader, model, epoch, data = None, attn_layer = -1):\n",
    "    model.eval()\n",
    "    y_pred_list, y_true_list, y_prob_list, loss_list = [], [], [], []\n",
    "    \n",
    "    logits_finetuned_ESM2 = []\n",
    "    representations_pertok_firstLayer_finetuned_ESM2, representations_mean_firstLayer_finetuned_ESM2, representations_bos_firstLayer_finetuned_ESM2 = [], [], []\n",
    "    representations_pertok_lastLayer_finetuned_ESM2, representations_mean_lastLayer_finetuned_ESM2, representations_bos_lastLayer_finetuned_ESM2 = [], [], []\n",
    "    \n",
    "    attentions_finetuned_ESM2, contacts_finetuned_ESM2, attentions_symm_finetuned_ESM2 = [], [], []\n",
    "    labels_finetuned_ESM2, strs_finetuned_ESM2 = [], []\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (labels, strs, masked_strs, toks, masked_toks, _) in enumerate(tqdm(test_dataloader)):\n",
    "            \n",
    "            labels_finetuned_ESM2.extend(labels)\n",
    "            strs_finetuned_ESM2.extend(strs)\n",
    "            \n",
    "            toks = toks.to(device)\n",
    "            labels = torch.FloatTensor(labels).to(device).reshape(-1, 1)\n",
    "            \n",
    "            outputs, results_finetuned_ESM2, _ = model(toks, need_head_weights=True, return_contacts=False, return_representation=True, return_attentions_symm = args.attentions_symm, return_attentions = args.attentions)\n",
    "#             print('args.attentions = ', args.attentions)\n",
    "#             print(results_finetuned_ESM2.keys())\n",
    "#             print(results_finetuned_ESM2['attentions'][:,attn_layer,:,:,:].detach().cpu().numpy().astype('float16').shape)\n",
    "            if args.logits: \n",
    "                try:\n",
    "                    logits_finetuned_ESM2 = np.vstack([logits_finetuned_ESM2, results_finetuned_ESM2['logits'].detach().cpu().numpy()])\n",
    "                except:\n",
    "                    logits_finetuned_ESM2 = results_finetuned_ESM2['logits'].detach().cpu().numpy()\n",
    "\n",
    "            if args.representations_pertok: \n",
    "                try:\n",
    "                    representations_pertok_firstLayer_finetuned_ESM2 = np.vstack([representations_pertok_firstLayer_finetuned_ESM2, results_finetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].detach().cpu().numpy()])\n",
    "                    representations_pertok_lastLayer_finetuned_ESM2 = np.vstack([representations_pertok_lastLayer_finetuned_ESM2, results_finetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].detach().cpu().numpy()])\n",
    "                except:\n",
    "                    representations_pertok_firstLayer_finetuned_ESM2 = results_finetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].detach().cpu().numpy()\n",
    "                    representations_pertok_lastLayer_finetuned_ESM2 = results_finetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].detach().cpu().numpy()\n",
    "\n",
    "            if args.representations_mean: \n",
    "                try:\n",
    "                    representations_mean_firstLayer_finetuned_ESM2 = np.vstack([representations_mean_firstLayer_finetuned_ESM2, results_finetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()])\n",
    "                    representations_mean_lastLayer_finetuned_ESM2 = np.vstack([representations_mean_lastLayer_finetuned_ESM2, results_finetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()])\n",
    "                except:\n",
    "                    representations_mean_firstLayer_finetuned_ESM2 = results_finetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()\n",
    "                    representations_mean_lastLayer_finetuned_ESM2 = results_finetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()\n",
    "\n",
    "            if args.representations_bos: \n",
    "                try:\n",
    "                    representations_bos_firstLayer_finetuned_ESM2 = np.vstack([representations_bos_firstLayer_finetuned_ESM2, results_finetuned_ESM2['representations'][0][:, 0].detach().cpu().numpy()])\n",
    "                    representations_bos_lastLayer_finetuned_ESM2 = np.vstack([representations_bos_lastLayer_finetuned_ESM2, results_finetuned_ESM2['representations'][layers][:, 0].detach().cpu().numpy()])\n",
    "                except:\n",
    "                    representations_bos_firstLayer_finetuned_ESM2 = results_finetuned_ESM2['representations'][0][:, 0].detach().cpu().numpy()\n",
    "                    representations_bos_lastLayer_finetuned_ESM2 = results_finetuned_ESM2['representations'][layers][:, 0].detach().cpu().numpy()\n",
    "                    \n",
    "\n",
    "            if args.attentions:\n",
    "                try:\n",
    "                    attentions_finetuned_ESM2 = np.vstack([attentions_finetuned_ESM2, results_finetuned_ESM2['attentions'][:,attn_layer,:,:,:].detach().cpu().numpy().astype('float16')])\n",
    "                except:\n",
    "                    attentions_finetuned_ESM2 = results_finetuned_ESM2['attentions'][:,attn_layer,:,:,:].detach().cpu().numpy().astype('float16')\n",
    "              \n",
    "\n",
    "            if args.contacts: \n",
    "                try:\n",
    "                    contacts_finetuned_ESM2 = np.vstack([contacts_finetuned_ESM2, results_finetuned_ESM2['contacts'].detach().cpu().numpy().astype('float16')])\n",
    "                except:\n",
    "                    contacts_finetuned_ESM2 = results_finetuned_ESM2['contacts'].detach().cpu().numpy().astype('float16')\n",
    "\n",
    "            if args.attentions_symm:\n",
    "                try:\n",
    "                    new_arr = results_finetuned_ESM2['attentions_symm'].detach().cpu().numpy().astype('float16')\n",
    "                    padded_ori_arr = np.pad(attentions_symm_finetuned_ESM2, ((0, 0), (0, new_arr.shape[-1] - attentions_symm_finetuned_ESM2.shape[-1]), (0, new_arr.shape[-1] - attentions_symm_finetuned_ESM2.shape[-1])), mode='constant')\n",
    "                    attentions_symm_finetuned_ESM2 = np.vstack([padded_ori_arr, new_arr])\n",
    "                except:\n",
    "                    attentions_symm_finetuned_ESM2 = results_finetuned_ESM2['attentions_symm'].detach().cpu().numpy().astype('float16')\n",
    "            y_true_list.extend(labels.cpu().reshape(-1).tolist())\n",
    "            y_pred = outputs.reshape(-1).cpu().detach().tolist()\n",
    "            y_pred_list.extend(y_pred)\n",
    "\n",
    "        print(f'Test: Epoch-{epoch} | ', end = '')\n",
    "        metrics = performances(y_true_list, y_pred_list)\n",
    "        if data is not None: \n",
    "            try:\n",
    "                data['y_pred'] = y_pred_list\n",
    "                data['y_true'] = y_true_list\n",
    "            except:\n",
    "                None\n",
    "    print('====Save Finetuned====') \n",
    "    if args.logits: \n",
    "        finetuned_outfilename_temp = f'{output_dir}/ESM2_finetuned/logits/{finetuned_outfilename}__logits.npz'\n",
    "        print(f'Saved to: {finetuned_outfilename_temp}')\n",
    "        np.savez(finetuned_outfilename_temp, \n",
    "                 sequences = strs_finetuned_ESM2,\n",
    "                 labels = labels_finetuned_ESM2,\n",
    "                 logits_ESM2 = logits_finetuned_ESM2)\n",
    "        del logits_finetuned_ESM2\n",
    "\n",
    "    if args.representations_pertok: \n",
    "        finetuned_outfilename_temp = f'{output_dir}/ESM2_finetuned/representations_pertok/{finetuned_outfilename}__representations_pertok.npz'\n",
    "        print(f'Saved to: {finetuned_outfilename_temp}')\n",
    "        np.savez(finetuned_outfilename_temp, \n",
    "                 sequences = strs_finetuned_ESM2,\n",
    "                 labels = labels_finetuned_ESM2,\n",
    "                 representations_pertok_firstLayer_ESM2 = representations_pertok_firstLayer_finetuned_ESM2,\n",
    "                 representations_pertok_lastLayer_ESM2 = representations_pertok_lastLayer_finetuned_ESM2)\n",
    "        del representations_pertok_firstLayer_finetuned_ESM2, representations_pertok_lastLayer_finetuned_ESM2\n",
    "\n",
    "    if args.representations_mean: \n",
    "        finetuned_outfilename_temp = f'{output_dir}/ESM2_finetuned/representations_mean/{finetuned_outfilename}__representations_mean.npz'\n",
    "        print(f'Saved to: {finetuned_outfilename_temp}')\n",
    "        np.savez(finetuned_outfilename_temp, \n",
    "                 sequences = strs_finetuned_ESM2,\n",
    "                 labels = labels_finetuned_ESM2,\n",
    "                 representations_mean_firstLayer_ESM2 = representations_mean_firstLayer_finetuned_ESM2,\n",
    "                 representations_mean_lastLayer_ESM2 = representations_mean_lastLayer_finetuned_ESM2)\n",
    "        del representations_mean_firstLayer_finetuned_ESM2, representations_mean_lastLayer_finetuned_ESM2\n",
    "\n",
    "    if args.representations_bos: \n",
    "        finetuned_outfilename_temp = f'{output_dir}/ESM2_finetuned/representations_bos/{finetuned_outfilename}__representations_bos.npz'\n",
    "        print(f'Saved to: {finetuned_outfilename_temp}')\n",
    "        np.savez(finetuned_outfilename_temp, \n",
    "                 sequences = strs_finetuned_ESM2,\n",
    "                 labels = labels_finetuned_ESM2,\n",
    "                 representations_bos_firstLayer_ESM2 = representations_bos_firstLayer_finetuned_ESM2,\n",
    "                 representations_bos_lastLayer_ESM2 = representations_bos_lastLayer_finetuned_ESM2)\n",
    "        del representations_bos_firstLayer_finetuned_ESM2, representations_bos_lastLayer_finetuned_ESM2\n",
    "\n",
    "    if args.attentions:    \n",
    "        finetuned_outfilename_temp = f'{output_dir}/ESM2_finetuned/attentions/{finetuned_outfilename}__attentions.npz'\n",
    "        print(f'Saved to: {finetuned_outfilename_temp}')\n",
    "        np.savez(finetuned_outfilename_temp, \n",
    "                 sequences = strs_finetuned_ESM2,\n",
    "                 labels = labels_finetuned_ESM2,\n",
    "                 attentions_ESM2 = attentions_finetuned_ESM2)\n",
    "        del attentions_finetuned_ESM2\n",
    "\n",
    "    if args.contacts:     \n",
    "        finetuned_outfilename_temp = f'{output_dir}/ESM2_finetuned/contacts/{finetuned_outfilename}__contacts.npz'\n",
    "        print(f'Saved to: {finetuned_outfilename_temp}')\n",
    "        np.savez(finetuned_outfilename_temp, \n",
    "                 sequences = strs_finetuned_ESM2,\n",
    "                 labels = labels_finetuned_ESM2,\n",
    "                 contacts_ESM2 = contacts_finetuned_ESM2)\n",
    "        del contacts_finetuned_ESM2\n",
    "\n",
    "    if args.attentions_symm:\n",
    "        finetuned_outfilename_temp = f'{output_dir}/ESM2_finetuned/attentions_symm/{finetuned_outfilename}__attentions_symm.npz'\n",
    "        print(f'Saved to: {finetuned_outfilename_temp}')\n",
    "        np.savez(finetuned_outfilename_temp, \n",
    "                 sequences = strs_finetuned_ESM2,\n",
    "                 labels = labels_finetuned_ESM2,\n",
    "                 attentions_symm_ESM2 = attentions_symm_finetuned_ESM2)\n",
    "        del attentions_symm_finetuned_ESM2\n",
    "\n",
    "    return metrics, data#, results_finetuned_ESM2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660e29d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████▉                       | 1362/3334 [17:07<25:27,  1.29it/s]"
     ]
    }
   ],
   "source": [
    "if args.finetune: # args.data_type == IRES Sample\n",
    "    # Finetuned Predictor model\n",
    "    predict_model = CNN_linear().to(device)\n",
    "        \n",
    "    predict_model.load_state_dict({k.replace('module.', ''):v for k,v in torch.load(modelfile).items()})\n",
    "    \n",
    "    metrics, data = finetuned_eval_step(dataloader, predict_model, epoch, data)\n",
    "\n",
    "    metrics = performances_to_pd(metrics)\n",
    "    print(metrics)\n",
    "\n",
    "    print('Saved to: ', f'{output_dir}/ESM2_finetuned/metrics/{finetuned_outfilename}.csv')\n",
    "    print('Saved to: ', f'{output_dir}/ESM2_finetuned/e_test/{finetuned_outfilename}.csv')\n",
    "    metrics.to_csv(f'{output_dir}/ESM2_finetuned/metrics/{finetuned_outfilename}.csv', index = True)\n",
    "    data.to_csv(f'{output_dir}/ESM2_finetuned/e_test/{finetuned_outfilename}.csv', index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f23ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.pretrained:\n",
    "    print('----Pretrained----')\n",
    "    if 'SISS' in modelfile:\n",
    "        ESM2_model = ESM2_SISS(num_layers = layers,\n",
    "                                 embed_dim = embed_dim,\n",
    "                                 attention_heads = heads,\n",
    "                                 alphabet = alphabet).to(device)\n",
    "    else:\n",
    "        ESM2_model = ESM2(num_layers = layers,\n",
    "                                 embed_dim = embed_dim,\n",
    "                                 attention_heads = heads,\n",
    "                                 alphabet = alphabet).to(device)\n",
    "    ESM2_model.load_state_dict(torch.load(args.esm2_modelfile, map_location=device), strict = False)\n",
    "\n",
    "#     logits_nonfinetuned_ESM2 = []\n",
    "#     representations_pertok_firstLayer_nonfinetuned_ESM2, representations_mean_firstLayer_nonfinetuned_ESM2, representations_bos_firstLayer_nonfinetuned_ESM2 = [], [], []\n",
    "#     representations_pertok_lastLayer_nonfinetuned_ESM2, representations_mean_lastLayer_nonfinetuned_ESM2, representations_bos_lastLayer_nonfinetuned_ESM2 = [], [], []\n",
    "#     attentions_nonfinetuned_ESM2, contacts_nonfinetuned_ESM2, attentions_symm_nonfinetuned_ESM2 = [], [], []\n",
    "    labels_nonfinetuned_ESM2, strs_nonfinetuned_ESM2 = [], []\n",
    "\n",
    "#     i = 0\n",
    "    with torch.no_grad():\n",
    "        for (labels, strs, masked_strs, toks, masked_toks, _) in tqdm(dataloader):\n",
    "            labels_nonfinetuned_ESM2.extend(labels)\n",
    "            strs_nonfinetuned_ESM2.extend(strs)\n",
    "\n",
    "            toks = toks.to(device)\n",
    "            results_nonfinetuned_ESM2 = ESM2_model(toks, repr_layers=repr_layers, need_head_weights=True, return_contacts=args.attentions_symm, return_representation=True, return_attentions_symm = args.attentions_symm, return_attentions = args.attentions)\n",
    "\n",
    "            if args.logits: \n",
    "                try:\n",
    "                    logits_nonfinetuned_ESM2 = np.vstack([logits_nonfinetuned_ESM2, results_nonfinetuned_ESM2['logits'].detach().cpu().numpy()])\n",
    "                except:\n",
    "                    logits_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['logits'].detach().cpu().numpy()\n",
    "\n",
    "            if args.representations_pertok: \n",
    "                try:\n",
    "                    representations_pertok_firstLayer_nonfinetuned_ESM2 = np.vstack([representations_pertok_firstLayer_nonfinetuned_ESM2, results_nonfinetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].detach().cpu().numpy()])\n",
    "                    representations_pertok_lastLayer_nonfinetuned_ESM2 = np.vstack([representations_pertok_lastLayer_nonfinetuned_ESM2, results_nonfinetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].detach().cpu().numpy()])\n",
    "                except:\n",
    "                    representations_pertok_firstLayer_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].detach().cpu().numpy()\n",
    "                    representations_pertok_lastLayer_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].detach().cpu().numpy()\n",
    "\n",
    "            if args.representations_mean: \n",
    "                try:\n",
    "                    representations_mean_firstLayer_nonfinetuned_ESM2 = np.vstack([representations_mean_firstLayer_nonfinetuned_ESM2, results_nonfinetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()])\n",
    "                    representations_mean_lastLayer_nonfinetuned_ESM2 = np.vstack([representations_mean_lastLayer_nonfinetuned_ESM2, results_nonfinetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()])\n",
    "                except:\n",
    "                    representations_mean_firstLayer_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['representations'][0][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()\n",
    "                    representations_mean_lastLayer_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['representations'][layers][:, 1 : max_seqlen + 1].mean(1).detach().cpu().numpy()\n",
    "\n",
    "            if args.representations_bos: \n",
    "                try:\n",
    "                    representations_bos_firstLayer_nonfinetuned_ESM2 = np.vstack([representations_bos_firstLayer_nonfinetuned_ESM2, results_nonfinetuned_ESM2['representations'][0][:, 0].detach().cpu().numpy()])\n",
    "                    representations_bos_lastLayer_nonfinetuned_ESM2 = np.vstack([representations_bos_lastLayer_nonfinetuned_ESM2, results_nonfinetuned_ESM2['representations'][layers][:, 0].detach().cpu().numpy()])\n",
    "                except:\n",
    "                    representations_bos_firstLayer_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['representations'][0][:, 0].detach().cpu().numpy()\n",
    "                    representations_bos_lastLayer_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['representations'][layers][:, 0].detach().cpu().numpy()\n",
    "                    \n",
    "            if args.attentions:\n",
    "                try:\n",
    "                    attentions_nonfinetuned_ESM2 = np.vstack([attentions_nonfinetuned_ESM2, results_nonfinetuned_ESM2['attentions'][:,attn_layer,:,:,:].detach().cpu().numpy().astype('float16')])\n",
    "                except:\n",
    "                    attentions_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['attentions'][:,attn_layer,:,:,:].detach().cpu().numpy().astype('float16')\n",
    "\n",
    "            if args.contacts: \n",
    "                try:\n",
    "                    contacts_nonfinetuned_ESM2 = np.vstack([contacts_nonfinetuned_ESM2, results_nonfinetuned_ESM2['contacts'].detach().cpu().numpy().astype('float16')])\n",
    "                except:\n",
    "                    contacts_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['contacts'].detach().cpu().numpy().astype('float16')\n",
    "\n",
    "            if args.attentions_symm:\n",
    "                try:\n",
    "                    new_arr = results_nonfinetuned_ESM2['attentions_symm'].detach().cpu().numpy().astype('float16')\n",
    "                    padded_ori_arr = np.pad(attentions_symm_nonfinetuned_ESM2, ((0, 0), (0, new_arr.shape[-1] - attentions_symm_nonfinetuned_ESM2.shape[-1]), (0, new_arr.shape[-1] - attentions_symm_nonfinetuned_ESM2.shape[-1])), mode='constant')\n",
    "                    attentions_symm_nonfinetuned_ESM2 = np.vstack([padded_ori_arr, new_arr])\n",
    "                except:\n",
    "                    attentions_symm_nonfinetuned_ESM2 = results_nonfinetuned_ESM2['attentions_symm'].detach().cpu().numpy().astype('float16')\n",
    "#                     print(f\"---{attentions_symm_nonfinetuned_ESM2.shape}---\")\n",
    "    print('====Save Pretrained====')\n",
    "    if args.logits: \n",
    "        nonfinetuned_outfilename_temp = f'{output_dir}/ESM2_pretrained/logits/{pretrained_outfilename}__logits.npz'\n",
    "        print(f'Saved to: {nonfinetuned_outfilename_temp}')\n",
    "        np.savez(nonfinetuned_outfilename_temp, \n",
    "                 sequences = strs_nonfinetuned_ESM2,\n",
    "                 labels = labels_nonfinetuned_ESM2,\n",
    "                 logits_ESM2 = logits_nonfinetuned_ESM2)\n",
    "        del logits_nonfinetuned_ESM2\n",
    "\n",
    "    if args.representations_pertok: \n",
    "        nonfinetuned_outfilename_temp = f'{output_dir}/ESM2_pretrained/representations_pertok/{pretrained_outfilename}__representations_pertok.npz'\n",
    "        print(f'Saved to: {nonfinetuned_outfilename_temp}')\n",
    "        np.savez(nonfinetuned_outfilename_temp, \n",
    "                 sequences = strs_nonfinetuned_ESM2,\n",
    "                 labels = labels_nonfinetuned_ESM2,\n",
    "                 representations_pertok_firstLayer_ESM2 = representations_pertok_firstLayer_nonfinetuned_ESM2,\n",
    "                 representations_pertok_lastLayer_ESM2 = representations_pertok_lastLayer_nonfinetuned_ESM2)\n",
    "        del representations_pertok_firstLayer_nonfinetuned_ESM2, representations_pertok_lastLayer_nonfinetuned_ESM2\n",
    "\n",
    "    if args.representations_mean: \n",
    "        nonfinetuned_outfilename_temp = f'{output_dir}/ESM2_pretrained/representations_mean/{pretrained_outfilename}__representations_mean.npz'\n",
    "        print(f'Saved to: {nonfinetuned_outfilename_temp}')\n",
    "        np.savez(nonfinetuned_outfilename_temp, \n",
    "                 sequences = strs_nonfinetuned_ESM2,\n",
    "                 labels = labels_nonfinetuned_ESM2,\n",
    "                 representations_mean_firstLayer_ESM2 = representations_mean_firstLayer_nonfinetuned_ESM2,\n",
    "                 representations_mean_lastLayer_ESM2 = representations_mean_lastLayer_nonfinetuned_ESM2)\n",
    "        del representations_mean_firstLayer_nonfinetuned_ESM2, representations_mean_lastLayer_nonfinetuned_ESM2\n",
    "\n",
    "    if args.representations_bos: \n",
    "        nonfinetuned_outfilename_temp = f'{output_dir}/ESM2_pretrained/representations_bos/{pretrained_outfilename}__representations_bos.npz'\n",
    "        print(f'Saved to: {nonfinetuned_outfilename_temp}')\n",
    "        np.savez(nonfinetuned_outfilename_temp, \n",
    "                 sequences = strs_nonfinetuned_ESM2,\n",
    "                 labels = labels_nonfinetuned_ESM2,\n",
    "                 representations_bos_firstLayer_ESM2 = representations_bos_firstLayer_nonfinetuned_ESM2,\n",
    "                 representations_bos_lastLayer_ESM2 = representations_bos_lastLayer_nonfinetuned_ESM2)\n",
    "        del representations_bos_firstLayer_nonfinetuned_ESM2, representations_bos_lastLayer_nonfinetuned_ESM2\n",
    "\n",
    "    if args.attentions:    \n",
    "        nonfinetuned_outfilename_temp = f'{output_dir}/ESM2_pretrained/attentions/{pretrained_outfilename}__attentions.npz'\n",
    "        print(f'Saved to: {nonfinetuned_outfilename_temp}')\n",
    "        np.savez(nonfinetuned_outfilename_temp, \n",
    "                 sequences = strs_nonfinetuned_ESM2,\n",
    "                 labels = labels_nonfinetuned_ESM2,\n",
    "                 attentions_ESM2 = attentions_nonfinetuned_ESM2)\n",
    "        del attentions_nonfinetuned_ESM2\n",
    "\n",
    "    if args.contacts:     \n",
    "        nonfinetuned_outfilename_temp = f'{output_dir}/ESM2_pretrained/contacts/{pretrained_outfilename}__contacts.npz'\n",
    "        print(f'Saved to: {nonfinetuned_outfilename_temp}')\n",
    "        np.savez(nonfinetuned_outfilename_temp, \n",
    "                 sequences = strs_nonfinetuned_ESM2,\n",
    "                 labels = labels_nonfinetuned_ESM2,\n",
    "                 contacts_ESM2 = contacts_nonfinetuned_ESM2)\n",
    "        del contacts_nonfinetuned_ESM2\n",
    "\n",
    "    if args.attentions_symm:\n",
    "        nonfinetuned_outfilename_temp = f'{output_dir}/ESM2_pretrained/attentions_symm/{pretrained_outfilename}__attentions_symm.npz'\n",
    "        print(f'Saved to: {nonfinetuned_outfilename_temp}')\n",
    "        np.savez(nonfinetuned_outfilename_temp, \n",
    "                 sequences = strs_nonfinetuned_ESM2,\n",
    "                 labels = labels_nonfinetuned_ESM2,\n",
    "                 attentions_symm_ESM2 = attentions_symm_nonfinetuned_ESM2)\n",
    "        del attentions_symm_nonfinetuned_ESM2\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f494f54b",
   "metadata": {},
   "source": [
    "predict_model = CNN_linear().to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in predict_model.parameters())\n",
    "print(\"Total number of parameters: \", total_params)\n",
    "#Total number of parameters:  1456920"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
